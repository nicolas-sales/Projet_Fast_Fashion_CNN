{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd              #analyse de donnees\n",
    "import numpy as np               #manipulation de tableaux ou calcul mathematiques\n",
    "import seaborn as sns            #visualisation de donnees\n",
    "import matplotlib.pyplot as plt  #visualisation les données\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18baca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/nico_/Desktop/IA School M2/Fast Fashion/visuelle2/sales.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849ee4b",
   "metadata": {},
   "source": [
    "Pour utiliser les images en entrée d'un modèle de classification binaire (polluant / non polluant), vous pouvez utiliser la bibliothèque Keras qui fournit des modèles de réseau de neurones pré-entraînés pour la classification d'images, comme le modèle VGG16.\n",
    "\n",
    "Voici les étapes générales à suivre:\n",
    "\n",
    "Préparez vos données d'entraînement: chargez les images à partir de votre dossier et créez deux listes: une liste contenant les images et une autre liste contenant les étiquettes de classe (0 ou 1 pour les images polluantes ou non polluantes).\n",
    "\n",
    "Divisez les données en ensembles d'entraînement et de validation. L'ensemble d'entraînement sera utilisé pour ajuster les poids du modèle, tandis que l'ensemble de validation sera utilisé pour évaluer les performances du modèle.\n",
    "\n",
    "Créez le modèle: utilisez le modèle VGG16 pré-entraîné fourni par Keras et ajoutez une couche de sortie à une seule unité avec une fonction d'activation sigmoïde pour la classification binaire.\n",
    "\n",
    "Compilez le modèle: définissez la fonction de perte (binary_crossentropy pour la classification binaire), l'optimiseur (par exemple, Adam) et les métriques d'évaluation (par exemple, précision).\n",
    "\n",
    "Entraînez le modèle: utilisez la méthode fit de Keras pour entraîner le modèle sur vos données d'entraînement.\n",
    "\n",
    "Évaluez le modèle: utilisez la méthode evaluate de Keras pour évaluer les performances du modèle sur vos données de validation.\n",
    "\n",
    "Faites des prédictions: utilisez la méthode predict de Keras pour prédire les étiquettes de classe de nouvelles images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c69055",
   "metadata": {},
   "source": [
    "# Création colonne matière polluante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8f668da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définission matières polluantes\n",
    "matieres_polluantes = ['acrylic','technical', 'polyviscous','fluid polyviscous','dark jean','light jean','nylon','paillettes']\n",
    "\n",
    "# Ajout d'une colonne \"matiere_polluante\" qui vaut 1 si la matière est polluante, sinon 0 \n",
    "data['matiere_polluante'] = [1 if matiere in matieres_polluantes else 0 for matiere in data['fabric']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c2d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['Unnamed: 0','external_code', 'retail', 'season', 'category', 'color','release_date', 'restock','fabric', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a2e675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\nico_\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c984fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (2.12.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nico_\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nico_\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b07f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>matiere_polluante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PE17/00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PE17/00002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PE17/00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PE17/00009.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PE17/00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_path  matiere_polluante\n",
       "0  PE17/00005.png                  1\n",
       "1  PE17/00002.png                  1\n",
       "2  PE17/00005.png                  1\n",
       "3  PE17/00009.png                  0\n",
       "4  PE17/00005.png                  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb6ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['matiere_polluante'] = df['matiere_polluante'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdcb82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraire les noms de fichiers\n",
    "new_paths = []\n",
    "for path in df['image_path']:\n",
    "    #new_path = path.split('/')[-1].split('.')[0]\n",
    "    new_path = path.split('/')[-1]\n",
    "    new_paths.append(new_path)\n",
    "\n",
    "# remplacer la colonne image_path par les nouveaux noms de fichiers extraits\n",
    "df['image_path'] = new_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b7b0361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>matiere_polluante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00009.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_path matiere_polluante\n",
       "0  00005.png                 1\n",
       "1  00002.png                 1\n",
       "2  00005.png                 1\n",
       "3  00009.png                 0\n",
       "4  00005.png                 1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e296ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106850, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4928c1b",
   "metadata": {},
   "source": [
    "# Test relation images dataframe avec images dossier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41854a76",
   "metadata": {},
   "source": [
    "-> Prend du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a02906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin d'accès absolu à votre dossier d'images\n",
    "image_dir = r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images'\n",
    "\n",
    "# Parcourir chaque ligne du dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # Charger l'image à partir du chemin\n",
    "    img = Image.open(os.path.join(image_dir, row[\"image_path\"]))\n",
    "    \n",
    "    # Afficher l'image\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Matière polluante : {}\".format(row[\"matiere_polluante\"]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.applications.vgg16 import VGG16\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle VGG16 pré-entraîné sans les couches fully-connected\n",
    "#base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18038e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une nouvelle couche fully-connected pour la classification binaire\n",
    "#x = Flatten()(base_model.output)\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#output_layer = Dense(1, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner le modèle VGG16 pré-entraîné et les nouvelles couches fully-connected\n",
    "#model = Model(inputs=base_model.input, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "#model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un objet ImageDataGenerator pour la mise à l'échelle et la rotation des images\n",
    "#datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, validation_split=0.2)\n",
    "\n",
    "# Charger les images d'entraînement et de validation\n",
    "#train_generator = datagen.flow_from_dataframe(\n",
    "#    dataframe=df,\n",
    " #   directory=r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images',\n",
    "  #  x_col=\"image_path\",\n",
    "   # y_col=\"matiere_polluante\",\n",
    "    #target_size=(224, 224),\n",
    "    #batch_size=32,\n",
    "    #subset=\"training\"\n",
    "#)\n",
    "\n",
    "#val_generator = datagen.flow_from_dataframe(\n",
    " #   dataframe=df,\n",
    "  #  directory=r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images',\n",
    "   # x_col=\"image_path\",\n",
    "    #y_col=\"matiere_polluante\",\n",
    "    #target_size=(224, 224),\n",
    "    #batch_size=32,\n",
    "    #subset=\"validation\"\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791154fb",
   "metadata": {},
   "source": [
    "# Je prends que les 2000 premières photos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09d77da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(n=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67b3a07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f1877",
   "metadata": {},
   "source": [
    "# Nouveau model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "defd7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d4fbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin d'accès au dossier d'images\n",
    "image_dir = r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc1e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\nico_\\anaconda3\\lib\\site-packages (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "868be299",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.31 MiB for an array with shape (757, 452, 4) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7292\\747592626.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image_path\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image_path\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"matiere_polluante\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.31 MiB for an array with shape (757, 452, 4) and data type uint8"
     ]
    }
   ],
   "source": [
    "# Chargement des images et des labels\n",
    "X = []\n",
    "y = []\n",
    "for index, row in df.iterrows():\n",
    "    img_path = os.path.join(image_dir, row[\"image_path\"])\n",
    "    img = Image.open(os.path.join(image_dir, row[\"image_path\"]))\n",
    "    img_array = np.array(img)\n",
    "    X.append(img_array)\n",
    "    y.append(row[\"matiere_polluante\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertion des listes en arrays numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split des données en train_set et test_set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preporocessing des images\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b1e9b",
   "metadata": {},
   "source": [
    "La fonction preprocess_input prend une image en entrée (sous forme d'un tableau de pixels) et effectue une série de transformations sur l'image pour la mettre dans un format compatible avec le modèle VGG16. Ces transformations incluent notamment :\n",
    "\n",
    "- Centrer les données : les données sont centrées autour de zéro en soustrayant la moyenne de l'ensemble des images de la base de données.\n",
    "- Réduire l'échelle : les données sont divisées par l'écart type de l'ensemble des images de la base de données.\n",
    "\n",
    "Ces étapes permettent de normaliser les données d'entrée pour que le modèle puisse apprendre de manière plus efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeca57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle VGG16 sans la dernière couche fully-connected\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db11ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'une nouvelle couche fully-connected pour la classification binaire\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b71bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83021d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score du modèle\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb52aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur de nouvelles images\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b366df",
   "metadata": {},
   "source": [
    "La fonction predict() de Keras utilise une fonction d'activation softmax, qui renvoie des probabilités normalisées pour chaque classe. Dans le cas d'une classification binaire, la sortie est un seul nombre représentant la probabilité de la classe positive (polluante).\n",
    "\n",
    "Si la probabilité est supérieure à 0,5, le modèle prédit la classe positive (polluante), sinon il prédit la classe négative (non polluante). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27ced4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4d993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78016fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781bf5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61faedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Chemin d'accès au dossier d'images\n",
    "image_dir = r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images'\n",
    "\n",
    "# Chargement des images et des labels\n",
    "X = []\n",
    "y = []\n",
    "for index, row in df.iterrows():\n",
    "    img_path = os.path.join(image_dir, row[\"image_path\"])\n",
    "    img = Image.open(os.path.join(image_dir, row[\"image_path\"]))\n",
    "    img_array = np.array(img)\n",
    "    X.append(img_array)\n",
    "    y.append(row[\"matiere_polluante\"])\n",
    "\n",
    "# Convertion des listes en arrays numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split des données en train_set et test_set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preporocessing des images\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "\n",
    "# Chargement du modèle VGG16 sans la dernière couche fully-connected\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Ajout d'une nouvelle couche fully-connected pour la classification binaire\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Définition du modèle final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Score du modèle\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "# Prédiction sur de nouvelles images\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7a43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb045fcb",
   "metadata": {},
   "source": [
    "# Avec correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d062d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 validated image filenames belonging to 2 classes.\n",
      "Found 400 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "20/50 [===========>..................] - ETA: 14:38 - loss: 27.7568 - accuracy: 0.7609"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nOSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nico_\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\nico_\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nico_\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 439, in load_img\n    img = img.convert(\"RGB\")\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 901, in convert\n    self.load()\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 276, in load\n    raise_oserror(err_code)\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 71, in raise_oserror\n    raise OSError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3849]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13556\\3287633570.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m# Entraînement du modèle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nOSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nico_\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\nico_\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nico_\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 439, in load_img\n    img = img.convert(\"RGB\")\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 901, in convert\n    self.load()\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 276, in load\n    raise_oserror(err_code)\n\n  File \"C:\\Users\\nico_\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 71, in raise_oserror\n    raise OSError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3849]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Chemin d'accès au dossier d'images\n",
    "image_dir = r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images'\n",
    "\n",
    "# Configuration du générateur d'images\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Chargement des images à partir du générateur\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df2,\n",
    "    directory=image_dir,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"matiere_polluante\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df2,\n",
    "    directory=image_dir,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"matiere_polluante\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Chargement du modèle VGG16 sans la dernière couche fully-connected\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Ajout d'une nouvelle couche fully-connected pour la classification binaire\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Définition du modèle final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Score du modèle\n",
    "score = model.evaluate(validation_generator)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "# Prédiction sur de nouvelles images\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'path/to/test/directory',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_pred = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6d666a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 validated image filenames belonging to 2 classes.\n",
      "Found 40 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 151s 30s/step - loss: 40.1388 - accuracy: 0.6125 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 154s 31s/step - loss: 4.8243 - accuracy: 0.7250 - val_loss: 0.3793 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 154s 31s/step - loss: 1.3479 - accuracy: 0.7375 - val_loss: 0.4246 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 156s 32s/step - loss: 0.5234 - accuracy: 0.8875 - val_loss: 0.2628 - val_accuracy: 0.9375\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 159s 32s/step - loss: 0.3575 - accuracy: 0.8875 - val_loss: 0.3240 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 154s 31s/step - loss: 0.3954 - accuracy: 0.8875 - val_loss: 0.3535 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 155s 31s/step - loss: 0.3868 - accuracy: 0.8875 - val_loss: 0.4607 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 154s 31s/step - loss: 0.3636 - accuracy: 0.8875 - val_loss: 0.3745 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 156s 31s/step - loss: 0.3258 - accuracy: 0.8875 - val_loss: 0.6386 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 158s 32s/step - loss: 0.3340 - accuracy: 0.8875 - val_loss: 0.3267 - val_accuracy: 0.9062\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.3313 - accuracy: 0.9000\n",
      "Test Loss: 0.3313257098197937\n",
      "Test Accuracy: 0.8999999761581421\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'path/to/test/directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13556\\727481273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# Prédiction sur de nouvelles images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m test_generator = test_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;34m'path/to/test/directory'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                 \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m         \"\"\"\n\u001b[1;32m-> 1648\u001b[1;33m         return DirectoryIterator(\n\u001b[0m\u001b[0;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'path/to/test/directory'"
     ]
    }
   ],
   "source": [
    "# Définition des chemins d'accès aux images\n",
    "image_dir = r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images'\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuration du générateur d'images\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Chargement des images à partir du générateur\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_dir,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"matiere_polluante\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=image_dir,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"matiere_polluante\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Chargement du modèle VGG16 sans la dernière couche fully-connected\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Ajout d'une nouvelle couche fully-connected pour la classification binaire\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Définition du modèle final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Score du modèle\n",
    "score = model.evaluate(validation_generator)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b090c7d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] Nom de répertoire non valide: 'C:\\\\Users\\\\nico_\\\\Desktop\\\\IA School M2\\\\Fast Fashion\\\\visuelle2\\\\images\\\\images\\\\00001.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13556\\4039667237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prédiction sur de nouvelles images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m test_generator = test_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;34mr'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images\\00001.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                 \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m         \"\"\"\n\u001b[1;32m-> 1648\u001b[1;33m         return DirectoryIterator(\n\u001b[0m\u001b[0;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] Nom de répertoire non valide: 'C:\\\\Users\\\\nico_\\\\Desktop\\\\IA School M2\\\\Fast Fashion\\\\visuelle2\\\\images\\\\images\\\\00001.png'"
     ]
    }
   ],
   "source": [
    "# Prédiction sur de nouvelles images\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\nico_\\Desktop\\IA School M2\\Fast Fashion\\visuelle2\\images\\images\\00001.png',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "437c4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Obtenez le chemin d'accès complet à l'image\n",
    "image_path = os.path.join(image_dir, '00001.png')\n",
    "\n",
    "# Chargez l'image\n",
    "img = Image.open(image_path).resize((224, 224))\n",
    "\n",
    "# Convertir l'image en tableau numpy\n",
    "x = np.array(img)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b81812b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\nico_\\anaconda3\\lib\\site-packages (2.12.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install keras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddd7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
